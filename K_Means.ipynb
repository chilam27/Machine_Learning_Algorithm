{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means From Scratch\n",
    "\n",
    "In this notebook, we will code the k-means model from scratch to understand the theory behind this commonly used unsupervised machine learning model.\n",
    "\n",
    "In the end, we will compare the result of the k-means model we build from scratch with the one from scikit-learn.\n",
    "\n",
    "YT: https://youtu.be/uLs-EYUpGAw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "The input data is a data frame and \"k\" (an integer specifying the number of clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first main function, we perform the steps as follows:\n",
    "- Transform \"data\" data frame into numpy arrays.\n",
    "- Initialize the centroids using `initialize_centroids` based on the \"data\" and the number of clusters (\"k\").\n",
    "- Use the next helper function, `get_labels`, to find labels for data points.\n",
    "- Update the clusters' centroids using the helper function `update_centroids`.\n",
    "- Repeat the steps above in a loop until the stopping criteria is met for the `should_stop` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def k_means(data, k):\n",
    "    data = data.to_numpy()\n",
    "    centroids = initialize_centroids(data, k)\n",
    "    \n",
    "    while True:\n",
    "        old_centroids = centroids\n",
    "        labels = get_labels(data, centroids)\n",
    "        centroids = update_centroids(data, labels, k)\n",
    "        \n",
    "        if should_stop(old_centroids, centroids):\n",
    "            break\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the `initialize_centroids` function is to initialize the centroids randomly within the region of all of the data points. We perform the steps as follows:\n",
    "- Initiate the minimum and maximum values of the x and y coordinates (\"x_min\", \"x_max\", \"y_min\", and \"y_max\") respectively with infinity values.\n",
    "- Loop through the data to get the actual minimum and maximum values of the x and y coordinates using the `min` and `max` functions.\n",
    "- Create a list of \"k\" numbers of \"centroids\" and for each of the centroids, we sample the x and y coordinates randomly (using the next helper function: `random_sample`) within the minimum and maximum range of all points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: initialize centroids\n",
    "def initialize_centroids(data, k):\n",
    "    x_min = y_min = float('inf')\n",
    "    x_max = y_max = float('-inf')\n",
    "    \n",
    "    for point in data:\n",
    "        x_min = min(point[0], x_min)\n",
    "        x_max = max(point[0], x_max)\n",
    "        y_min = min(point[1], y_min)\n",
    "        y_max = max(point[1], y_max)\n",
    "    centroids = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        centroids.append([random_sample(x_min, x_max), random_sample(y_min, y_max)])\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `random_sample`, we sample a random value between the low and high boundaries. We use the `random.random` function to sample a number uniformly distributed between 0 and 1. Then we scale the number so its value will be between low and high boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: random sample\n",
    "def random_sample(low, high):\n",
    "    return low + (high - low) * random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `get_labels` function to get labels for each data point:\n",
    "- Initiate an outer loop where it goes through all the data points.\n",
    "- Initiate an inner loop where it goes through all the centroids.\n",
    "- Set the first minimum distance (\"min_dist\") as infinity.\n",
    "- Use `get_distance` to find the new distance between the data point and the centroid.\n",
    "- Update the minimum distance and assign a label to the new centroid when we find a closer point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: get labels\n",
    "def get_labels(data, centroids):\n",
    "    labels = []\n",
    "    for point in data:\n",
    "        min_dist = float('inf')\n",
    "        label = None\n",
    "        for i, centroid in enumerate(centroids):\n",
    "            new_dist = get_distance(point, centroid)\n",
    "            if min_dist > new_dist:\n",
    "                min_dist = new_dist\n",
    "                label = i\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a widely used Euclidean distant as a distance metric in the `get_distance` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: get distance\n",
    "def get_distance(p1, p2):\n",
    "    a = 0\n",
    "    for n in range(len(p1)):\n",
    "        a += (p1[n] - p2[n]) ** 2\n",
    "    return (a) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `update_centroids` function, we update the centroids using the mean of the points that are assigned to each centroid:\n",
    "- Initialize \"k\" number of \"new_centroids\" and \"counts\" of points that belong to each cluster.\n",
    "- Loop through the data points to add the data vectors to the new centroids and increment the \"counts\" according to the label initiated in the step above.\n",
    "- Loop through all the newly computed centroids to compute the average of x and y coordinates by dividing the sum data vectors by the \"counts\" to obtain the new centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: update centroids\n",
    "def update_centroids(data, labels, k):\n",
    "    new_centroids = [[0, 0] for i in range(k)]\n",
    "    counts = [0] * k\n",
    "    \n",
    "    for point, label in zip(data, labels):\n",
    "        new_centroids[label][0] += point[0]\n",
    "        new_centroids[label][1] += point[1]\n",
    "        counts[label] += 1\n",
    "        \n",
    "    for i, (x, y) in enumerate(new_centroids):\n",
    "        new_centroids[i] = (x / counts[i], y/ counts[i])\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `should_stop` function, we decide the stopping criteria to exit the loop by comparing the total movement (the Euclidean distance of new and old centroids) across all centroids with a threshold (\"1e-5\"). The function returns true if the total movement is less than the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: should stop\n",
    "def should_stop(old_centroids, new_centroids, threshold = 1e-5):\n",
    "    total_movement = 0\n",
    "    for old_point, new_point in zip(old_centroids, new_centroids):\n",
    "        total_movement += get_distance(old_point, new_point)\n",
    "    return total_movement < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "For this section, we will be using the popular Iris dataset to perform the comparison between our k-means model and the scikit-learn `KMeans` model. The metric we will use for our comparison will be the outputted label from both models. Because our model can only take in two-dimensional points data, we will use only two variables (\"SepalLengthCm\" and \"SepalWidthCm\") for the models to cluster the data. The metric we will use for our comparison will be the outputted labels from both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('data/Iris_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate independent and dependent variables\n",
    "X = df[[\"SepalLengthCm\", \"SepalWidthCm\"]] # independent variables\n",
    "y = df[\"Species\"] # dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm\n",
       "0       0.222222      0.625000\n",
       "1       0.166667      0.416667\n",
       "2       0.111111      0.500000\n",
       "3       0.083333      0.458333\n",
       "4       0.194444      0.666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize data\n",
    "X_normalized = (X - X.min()) / (X.max() - X.min()) # min-max normalization\n",
    "X_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theon\\Anaconda3\\envs\\mlalgorithm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\theon\\Anaconda3\\envs\\mlalgorithm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels of [3, 18, 135] Indexes:  ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "K-mean Model's Labels of [3, 18, 135] Indexes:  [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# sklearn k-means model\n",
    "model_sklearn  = KMeans(n_clusters = 3).fit(X_normalized)\n",
    "\n",
    "print(\"Original Labels of [3, 18, 135] Indexes: \", [y[i] for i in (3, 81, 135)])\n",
    "print(\"K-mean Model's Labels of [3, 18, 135] Indexes: \", [model_sklearn.labels_[i] for i in (3, 81, 135)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels of [3, 18, 135] Indexes:  ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "K-mean Model's Labels of [3, 18, 135] Indexes:  [1, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "# our k-means model\n",
    "model_scratch = k_means(X_normalized, k = 3)\n",
    "\n",
    "print(\"Original Labels of [3, 18, 135] Indexes: \", [y[i] for i in (3, 81, 135)])\n",
    "print(\"K-mean Model's Labels of [3, 18, 135] Indexes: \", [model_scratch[i] for i in (3, 81, 135)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results above, both models are able to identify the indexes belonging to different groups. Hence, we have successfully built the k-means model from scratch!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlalgorithm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
